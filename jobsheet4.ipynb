{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e68513bc",
   "metadata": {},
   "source": [
    "### Praktikum D1 — Inisialisasi Kamera dan Akuisisi Citra "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61afcef",
   "metadata": {},
   "source": [
    "Praktikum ini merupakan tahap awal dalam mengenal sistem visi komputer. Mahasiswa akan  belajar membuka perangkat kamera, menampilkan citra secara berkelanjutan, serta  memastikan bahwa perangkat keras dan perangkat lunak dapat berkomunikasi dengan baik.  Proses ini menjadi fondasi bagi semua eksperimen berikutnya yang menggunakan aliran video  sebagai input utama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4333bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, time \n",
    "\n",
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "if not cap.isOpened(): \n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka. Coba index 1/2.\") \n",
    "\n",
    "frames, t0 = 0, time.time() \n",
    "\n",
    "while True: \n",
    "    ok, frame = cap.read() \n",
    "    if not ok: \n",
    "        break \n",
    "    frames += 1 \n",
    "\n",
    "    if time.time() - t0 >= 1.0: \n",
    "        cv2.setWindowTitle(\"Preview\", f\"Preview (FPS ~ {frames})\") \n",
    "        frames, t0 = 0, time.time() \n",
    "    cv2.imshow(\"Preview\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break \n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b83778b",
   "metadata": {},
   "source": [
    "### Praktikum D2 — Deteksi Pose dan Analisis Sudut "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63bab02",
   "metadata": {},
   "source": [
    "MediaPipe Pose menyediakan 33 landmark tubuh yang dapat digunakan untuk menganalisis  posisi dan orientasi manusia. Dalam praktikum ini, mahasiswa akan mengimplementasikan  algoritma deteksi pose dan menghitung sudut sendi berdasarkan koordinat tiga titik utama  tubuh menggunakan prinsip geometri vektor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f859a580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.20\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np\n",
    "import mediapipe\n",
    "from cvzone.PoseModule import PoseDetector\n",
    "print(mediapipe.__version__)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
    "\n",
    "detector = PoseDetector(staticMode=False, modelComplexity=1,\n",
    "                        enableSegmentation=False, detectionCon=0.5,\n",
    "                        trackCon=0.5)\n",
    "\n",
    "while True:\n",
    "    # Tangkap setiap frame dari webcam\n",
    "    success, img = cap.read()\n",
    "    if not success: break\n",
    "\n",
    "    # Temukan pose manusia dalam frame\n",
    "    img = detector.findPose(img)\n",
    "\n",
    "    # Temukan landmark, bounding box, dan pusat tubuh dalam frame\n",
    "    # Set draw=True untuk menggambar landmark dan bounding box pada gambar\n",
    "    lmList, bboxInfo = detector.findPosition(img, draw=True,\n",
    "                                             bboxWithHands=False)\n",
    "\n",
    "    # Periksa apakah ada landmark tubuh yang terdeteksi\n",
    "    if lmList:\n",
    "        # Dapatkan pusat bounding box di sekitar tubuh\n",
    "        center = bboxInfo[\"center\"]\n",
    "        # Gambar lingkaran di pusat bounding box\n",
    "        cv2.circle(img, center, 5, (255, 0, 255), cv2.FILLED)\n",
    "\n",
    "        # Hitung jarak antara landmark 11 dan 15 dan gambarkan pada gambar\n",
    "        length, img, info = detector.findDistance(lmList[11][0:2],\n",
    "                                                  lmList[15][0:2],\n",
    "                                                  img=img,\n",
    "                                                  color=(255, 0, 0),\n",
    "                                                  scale=10)\n",
    "\n",
    "        # Hitung sudut antara landmark 11, 13, dan 15 dan gambarkan pada gambar\n",
    "        angle, img = detector.findAngle(lmList[11][0:2],\n",
    "                                        lmList[13][0:2],\n",
    "                                        lmList[15][0:2],\n",
    "                                        img=img,\n",
    "                                        color=(0, 0, 255),\n",
    "                                        scale=10)\n",
    "\n",
    "        # Periksa apakah sudut mendekati 50 derajat dengan offset 10\n",
    "        isCloseAngle50 = detector.angleCheck(myAngle=angle,\n",
    "                                             targetAngle=50,\n",
    "                                             offset=10)\n",
    "\n",
    "        # Cetak hasil pemeriksaan sudut\n",
    "        print(isCloseAngle50)\n",
    "\n",
    "    cv2.imshow(\"Pose + Angle\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0747842",
   "metadata": {},
   "source": [
    "### Praktikum D3 — Deteksi Wajah dan Analisis Kedipan Mata "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cecdf1e",
   "metadata": {},
   "source": [
    "Face Mesh memetakan 468 titik pada wajah, termasuk titik di sekitar mata. Praktikum ini  memperkenalkan konsep Eye Aspect Ratio (EAR), yaitu rasio antara jarak vertikal dan  horizontal mata yang digunakan untuk menentukan apakah mata dalam kondisi terbuka atau  tertutup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f08965fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "from cvzone.FaceMeshModule import FaceMeshDetector\n",
    "\n",
    "# Indeks landmark mata kiri yang digunakan (MediaPipe face mesh indices)\n",
    "L_TOP, L_BOTTOM, L_LEFT, L_RIGHT = 159, 145, 33, 133 \n",
    "\n",
    "# Fungsi untuk menghitung jarak Euclidean antara dua titik (p1 dan p2)\n",
    "def dist(p1, p2): \n",
    "    return np.linalg.norm(np.array(p1) - np.array(p2)) \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
    "\n",
    "# Inisialisasi objek FaceMeshDetector\n",
    "detector = FaceMeshDetector(staticMode=False, maxFaces=2,\n",
    "                            minDetectionCon=0.5, minTrackCon=0.5)\n",
    "\n",
    "# Variabel untuk menghitung kedipan sederhana\n",
    "blink_count = 0 \n",
    "closed_frames = 0 \n",
    "CLOSED_FRAMES_THRESHOLD = 3 # Jumlah frame berturut-turut untuk dianggap kedipan \n",
    "EYE_AR_THRESHOLD = 0.20 # Ambang batas Eye Aspect Ratio (EAR) untuk menilai mata tertutup \n",
    "is_closed = False \n",
    "\n",
    "while True:\n",
    "    ok, img = cap.read()\n",
    "    if not ok: break\n",
    "    \n",
    "    # Temukan Face Mesh di dalam frame\n",
    "    img, faces = detector.findFaceMesh(img, draw=True) \n",
    "    \n",
    "    if faces: \n",
    "        face = faces[0] # Ambil data untuk wajah pertama (list of 468 (x,y) landmarks)\n",
    "        \n",
    "        # Hitung jarak vertikal dan horizontal mata kiri\n",
    "        v = dist(face[L_TOP], face[L_BOTTOM]) \n",
    "        h = dist(face[L_LEFT], face[L_RIGHT]) \n",
    "        \n",
    "        # Hitung Eye Aspect Ratio (EAR)\n",
    "        # 1e-8 ditambahkan untuk menghindari pembagian dengan nol\n",
    "        ear = v / (h + 1e-8) \n",
    "        \n",
    "        # Tampilkan nilai EAR pada frame\n",
    "        cv2.putText(img, f\"EAR(L): {ear:.3f}\", (20,40), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,255), 2) \n",
    "        \n",
    "        # Logika counter kedipan sederhana:\n",
    "        if ear < EYE_AR_THRESHOLD: \n",
    "            closed_frames += 1 \n",
    "            \n",
    "            # Jika mata tertutup cukup lama DAN belum dicatat sebagai kedipan baru\n",
    "            if closed_frames >= CLOSED_FRAMES_THRESHOLD and not is_closed: \n",
    "                blink_count += 1 \n",
    "                is_closed = True \n",
    "        else: \n",
    "            # Jika mata terbuka, reset penghitung frame tertutup\n",
    "            closed_frames = 0 \n",
    "            is_closed = False \n",
    "\n",
    "        # Tampilkan jumlah kedipan pada frame\n",
    "        cv2.putText(img, f\"Blink: {blink_count}\", (20,70), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2) \n",
    "        \n",
    "    cv2.imshow(\"FaceMesh + EAR\", img) \n",
    "    \n",
    "    # Keluar jika tombol 'q' ditekan\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05398721",
   "metadata": {},
   "source": [
    "### Praktikum D4 — Deteksi Tangan dan Penghitungan Jumlah Jari "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a943780a",
   "metadata": {},
   "source": [
    "MediaPipe Hands mendeteksi 21 landmark pada setiap tangan. Berdasarkan hubungan antara  ujung jari (tip) dan sendi bawahnya (PIP), dapat ditentukan apakah jari tersebut dalam posisi  terangkat atau tidak. Pendekatan ini digunakan untuk menghitung jumlah jari terbuka. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "539f8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
    "\n",
    "# Inisialisasi HandDetector\n",
    "detector = HandDetector(staticMode=False, maxHands=1, modelComplexity=1,\n",
    "                        detectionCon=0.5, minTrackCon=0.5)\n",
    "\n",
    "while True:\n",
    "    ok, img = cap.read()\n",
    "    if not ok: break\n",
    "    \n",
    "    # Temukan tangan dalam frame. flipType=True memirorkan tampilan UI.\n",
    "    hands, img = detector.findHands(img, draw=True, flipType=True) \n",
    "    \n",
    "    if hands: \n",
    "        hand = hands[0] # Ambil data tangan pertama\n",
    "        \n",
    "        # Cek jari mana yang terangkat (list [0/1] sepanjang 5)\n",
    "        fingers = detector.fingersUp(hand) \n",
    "        \n",
    "        # Hitung jumlah jari yang terangkat\n",
    "        count = sum(fingers) \n",
    "        \n",
    "        # Tampilkan jumlah jari dan status jari pada frame\n",
    "        cv2.putText(img, f\"Fingers: {count} {fingers}\", (20,40), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2) \n",
    "    \n",
    "    cv2.imshow(\"Hands + Fingers\", img) \n",
    "    \n",
    "    # Keluar dari loop jika tombol 'q' ditekan\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break \n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c03730b",
   "metadata": {},
   "source": [
    "### Praktikum D5 — Pengenalan Gestur Tangan (Hand Gesture Recognition) \n",
    "Gestur tangan merupakan salah satu bentuk komunikasi nonverbal yang dapat diterjemahkan  oleh sistem visi komputer. Dalam praktikum ini, mahasiswa akan merancang aturan  geometris untuk mengenali gestur dasar seperti “Thumbs Up”, “OK”, dan “Rock–Paper– Scissors”. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc265c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "\n",
    "# Fungsi untuk menghitung jarak Euclidean antara dua titik (a dan b)\n",
    "def dist(a, b): \n",
    "    return np.linalg.norm(np.array(a) - np.array(b)) \n",
    "\n",
    "def classify_gesture(hand):\n",
    "    # Dapatkan 21 landmark (x,y,z) tangan\n",
    "    lm = hand[\"lmList\"] \n",
    "    if not lm:\n",
    "        return \"NO_HAND\"\n",
    "        \n",
    "    wrist = np.array(lm[0][:2]) \n",
    "    thumb_tip = np.array(lm[4][:2]) \n",
    "    index_tip = np.array(lm[8][:2]) \n",
    "    middle_tip = np.array(lm[12][:2]) \n",
    "    ring_tip = np.array(lm[16][:2]) \n",
    "    pinky_tip = np.array(lm[20][:2]) \n",
    "    \n",
    "    # Hitung rata-rata jarak dari ujung jari ke pergelangan tangan (wrist)\n",
    "    # Ini membantu membedakan CLOSED (ROCK) dari OPEN (PAPER)\n",
    "    r_mean = np.mean([dist(index_tip, wrist), dist(middle_tip, wrist),\n",
    "                      dist(ring_tip, wrist), dist(pinky_tip, wrist), \n",
    "                      dist(thumb_tip, wrist)]) \n",
    "    \n",
    "    # --- Aturan Klasifikasi ---\n",
    "    \n",
    "    # 1. OK (Jari telunjuk dan ibu jari bertemu)\n",
    "    if dist(thumb_tip, index_tip) < 35: \n",
    "        return \"OK\" \n",
    "    \n",
    "    # 2. THUMBS_UP (Ibu jari tinggi dan jauh dari pergelangan tangan)\n",
    "    # Perlu akses ke fingersUp untuk validasi yang lebih baik (misalnya, jari lain tertutup)\n",
    "    if (thumb_tip[1] < wrist[1] - 40) and (dist(thumb_tip, wrist) > 0.8 * dist(index_tip, wrist)): \n",
    "        return \"THUMBS_UP\" \n",
    "    \n",
    "    # 3. ROCK (Tangan terkepal) - Jarak rata-rata pendek\n",
    "    if r_mean < 120: \n",
    "        return \"ROCK\" \n",
    "    \n",
    "    # 4. PAPER (Tangan terbuka) - Jarak rata-rata panjang\n",
    "    if r_mean > 200: \n",
    "        return \"PAPER\" \n",
    "    \n",
    "    # 5. V/PEACE (Jari telunjuk dan tengah terbuka, yang lain tertutup)\n",
    "    # Untuk validasi ini, kita memerlukan hasil dari fingersUp.\n",
    "    # Kita asumsikan lmList[16] adalah landmark tip jari.\n",
    "    # Namun, karena bagian ini terpotong di input Anda, \n",
    "    # kita akan lengkapi dengan asumsi dasar:\n",
    "    \n",
    "    # JIKA Kode Lanjutan Anda Mencoba Mendeteksi V/PEACE:\n",
    "    # if dist(index_tip, wrist) > 180 and dist(middle_tip, wrist) > 180 and ... \n",
    "    \n",
    "    # Asumsi default jika tidak ada aturan yang cocok\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened(): \n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka.\") \n",
    "\n",
    "# Inisialisasi HandDetector: maxHands=1 untuk mendeteksi satu tangan saja\n",
    "detector = HandDetector(staticMode=False, maxHands=1, modelComplexity=1, \n",
    "                        detectionCon=0.5, minTrackCon=0.5) \n",
    "\n",
    "while True:\n",
    "    ok, img = cap.read() \n",
    "    if not ok: break \n",
    "    \n",
    "    # Temukan tangan. flipType=True disarankan untuk tampilan cermin.\n",
    "    hands, img = detector.findHands(img, draw=True, flipType=True) \n",
    "    \n",
    "    gesture = \"Mencari Tangan...\"\n",
    "    \n",
    "    if hands: \n",
    "        hand = hands[0] # Data tangan pertama\n",
    "        \n",
    "        # Klasifikasikan gerakan tangan\n",
    "        gesture = classify_gesture(hand)\n",
    "\n",
    "    # Tampilkan hasil klasifikasi gerakan\n",
    "    cv2.putText(img, f\"Gesture: {gesture}\", (20, 40), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 0), 2) \n",
    "    \n",
    "    cv2.imshow(\"Gesture Recognition\", img) \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break \n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc993293",
   "metadata": {},
   "source": [
    "### Praktikum D6 — Analisis Gerakan Tubuh dan Penghitung Aktivitas \n",
    "Praktikum ini mengintegrasikan kemampuan deteksi pose dengan logika analisis gerakan.  Mahasiswa akan menerapkan penghitungan sudut dan rasio jarak untuk mengenali dua posisi  utama (naik dan turun), serta menerapkan teknik debounce untuk menghindari penghitungan  ganda. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5aa1f02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mulai merekam video ke file: pose_counter__20251207_100806.mp4\n",
      "Resolusi: 640x480, FPS: 30.00\n",
      "Selesai merekam dan menutup semua jendela.\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np \n",
    "from collections import deque\n",
    "from cvzone.PoseModule import PoseDetector \n",
    "# Import time untuk membuat nama file yang unik (opsional)\n",
    "import time \n",
    "\n",
    "# --- Konfigurasi ---\n",
    "MODE = \"squat\" \n",
    "KNEE_DOWN, KNEE_UP = 120, 180 \n",
    "DOWN_R, UP_R = 0.85, 1.00 \n",
    "SAMPLE_OK = 4 \n",
    "\n",
    "cap = cv2.VideoCapture(0) \n",
    "if not cap.isOpened(): \n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka.\") \n",
    "\n",
    "# 1. MENDAPATKAN PROPERTI VIDEO & INISIALISASI VIDEO WRITER\n",
    "FRAME_WIDTH = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "FRAME_HEIGHT = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS)\n",
    "if FPS == 0:\n",
    "    FPS = 30 \n",
    "\n",
    "OUTPUT_FILENAME = f'pose_counter__{time.strftime(\"%Y%m%d_%H%M%S\")}.mp4'\n",
    "FOURCC = cv2.VideoWriter_fourcc(*'mp4v') # Codec untuk file .mp4\n",
    "out = cv2.VideoWriter(OUTPUT_FILENAME, FOURCC, FPS, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "\n",
    "print(f\"Mulai merekam video ke file: {OUTPUT_FILENAME}\")\n",
    "print(f\"Resolusi: {FRAME_WIDTH}x{FRAME_HEIGHT}, FPS: {FPS:.2f}\")\n",
    "\n",
    "# Inisialisasi PoseDetector\n",
    "detector = PoseDetector(staticMode=False, modelComplexity=1, \n",
    "                        enableSegmentation=False, detectionCon=0.5, trackCon=0.5) \n",
    "\n",
    "count, state = 0, \"up\" \n",
    "debounce = deque(maxlen=6) \n",
    "\n",
    "# Fungsi untuk menghitung rasio push-up\n",
    "def ratio_pushup(lm): \n",
    "    sh = np.array(lm[11][1:3]) # Shoulder \n",
    "    wr = np.array(lm[15][1:3]) # Wrist \n",
    "    hp = np.array(lm[23][1:3]) # Hip \n",
    "    return np.linalg.norm(sh - wr) / (np.linalg.norm(sh - hp) + 1e-8) \n",
    "\n",
    "while True: \n",
    "    ok, img = cap.read()\n",
    "    if not ok: break \n",
    "    \n",
    "    img = detector.findPose(img, draw=True) \n",
    "    lmList, _ = detector.findPosition(img, draw=False) \n",
    "    flag = None \n",
    "    \n",
    "    if lmList: \n",
    "        if MODE == \"squat\":\n",
    "            # Logika Squat\n",
    "            angL, img = detector.findAngle(lmList[23][0:2], lmList[25][0:2], lmList[27][0:2], \n",
    "                                           img=img, color=(0, 0, 255), scale=10) \n",
    "            angR, img = detector.findAngle(lmList[24][0:2], lmList[26][0:2], lmList[28][0:2], \n",
    "                                           img=img, color=(0, 255, 0), scale=10) \n",
    "            ang = (angL + angR) / 2.0 \n",
    "            \n",
    "            if ang < KNEE_DOWN: \n",
    "                flag = \"down\" \n",
    "            elif ang > KNEE_UP: \n",
    "                flag = \"up\" \n",
    "                \n",
    "            cv2.putText(img, f\"Knee: {ang:5.1f}\", (20,70), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2) \n",
    "                        \n",
    "        else: \n",
    "            # Logika Push-up\n",
    "            r = ratio_pushup(lmList) \n",
    "            \n",
    "            if r < DOWN_R: \n",
    "                flag = \"down\" \n",
    "            elif r > UP_R: \n",
    "                flag = \"up\" \n",
    "                \n",
    "            cv2.putText(img, f\"Ratio: {r:4.2f}\", (20,70), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,255), 2) \n",
    "        \n",
    "        # Debounce dan Counter Logika\n",
    "        debounce.append(flag) \n",
    "        \n",
    "        if debounce.count(\"down\") >= SAMPLE_OK and state == \"up\": \n",
    "            state = \"down\"\n",
    "            \n",
    "        if debounce.count(\"up\") >= SAMPLE_OK and state == \"down\":\n",
    "            state = \"up\"\n",
    "            count += 1 \n",
    "            \n",
    "    # Tampilan UI\n",
    "    cv2.putText(img, f\"Mode: {MODE.upper()} Count: {count}\", (20,40), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2) \n",
    "    cv2.putText(img, f\"State: {state}\", (20,100), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2) \n",
    "    \n",
    "    # 2. TULIS FRAME KE FILE VIDEO\n",
    "    out.write(img)\n",
    "\n",
    "    cv2.imshow(\"Pose Counter\", img) \n",
    "    \n",
    "    # Input Kontrol\n",
    "    key = cv2.waitKey(1) & 0xFF \n",
    "    if key == ord('q'): break \n",
    "    \n",
    "    if key == ord('m'): \n",
    "        MODE = \"pushup\" if MODE == \"squat\" else \"squat\"\n",
    "        count, state = 0, \"up\"\n",
    "        debounce.clear()\n",
    "\n",
    "# 3. PENUTUP\n",
    "cap.release() \n",
    "out.release() # Penting: Tutup VideoWriter\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Selesai merekam dan menutup semua jendela.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
